# ImageCaptioning 

A thesis inspired by the paper “Deep Visual-Semantic Alignments for Generating Images Descriptions.” by Andrej Karpathy and Li Fei-Fei presents on a model that generates natural language descriptions of images and their regions using Convolutional and Recurrent Neural Networks.

## Introduction

We trained a model using Python that generates a sentence based on the objects it recognizes in an image. We used images from the Microsoft COCO dataset where a pre-trained neural network helped identify objects in the image. The descriptions of these objects were fed into another neural net that arranged these descriptions sequentially to generate a sentence as an output. 
